name: 微调 Qwen-7B 高中学习助手（FastChat + LoRA）
on:
  push:
    branches: [ main ]
  workflow_dispatch:

jobs:
  train-qwen-lora:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      packages: write
    steps:
      - name: 拉取代码
        uses: actions/checkout@v4

      - name: 配置 Python 3.10
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          cache: 'pip'

      # ========== 修复核心步骤：调整依赖安装顺序 ==========
      - name: 优先安装 PyTorch（适配 CUDA 11.8）
        run: |
          pip install --upgrade pip
          # 安装对应 CUDA 11.8 的 PyTorch（避免版本不兼容）
          pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118

      - name: 安装 flash-attn（用预编译包，跳过本地编译）
        run: |
          # 使用 huggingface 源的预编译 wheel，避免编译依赖问题
          # pip install flash-attn==2.8.3 --no-build-isolation --index-url https://download.pytorch.org/whl/cu118
          pip install flash-attn==2.8.3 --no-build-isolation --find-links https://download.pytorch.org/whl/cu118 --trusted-host download.pytorch.org
      - name: 安装 FastChat 及其他训练依赖
        run: |
          # 安装 FastChat（无需再单独装 flash-attn，已提前安装）
          pip install -e .
          # 安装剩余依赖
          pip install transformers==4.37.2 accelerate==0.27.1 peft==0.8.2 datasets==2.14.6
          pip install huggingface-hub==0.20.3 sentencepiece==0.1.99
      # ========== 修复结束 ==========

      - name: 安装 CUDA 11.8
        uses: Jimver/cuda-toolkit@v0.2.10
        with:
          cuda: '11.8'

      - name: 登录 Hugging Face Hub
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          huggingface-cli login --token $HF_TOKEN

      - name: 下载 Qwen-7B 模型
        run: |
          huggingface-cli download Qwen/Qwen-7B \
            --local-dir ./models/Qwen-7B \
            --local-dir-use-symlinks False

      - name: 启动 Qwen 模型 LoRA 微调
        run: |
          python -m fastchat.train.train_lora \
            --model_name_or_path ./models/Qwen-7B \
            --data_path ./data/highschool_qa.json \
            --output_dir ./output/qwen-7b-highschool-lora \
            --per_device_train_batch_size=4 \
            --gradient_accumulation_steps=4 \
            --learning_rate=2e-4 \
            --num_train_epochs=3 \
            --logging_steps=10 \
            --save_steps=100 \
            --fp16=True \
            --lora_r=8 \
            --lora_alpha=16 \
            --lora_dropout=0.05 \
            --target_modules="q_proj,v_proj,k_proj,o_proj,gate_proj,up_proj,down_proj" \
            --peft_model_id ${{ secrets.HF_USERNAME }}/qwen-7b-highschool-qa \
            --push_to_hub=True

      - name: 推送合并后的模型到 Hugging Face
        if: success()
        run: |
          python -m fastchat.model.push_to_hub \
            --model-path ./models/Qwen-7B \
            --lora-path ./output/qwen-7b-highschool-lora \
            --repo-id ${{ secrets.HF_USERNAME }}/qwen-7b-highschool-qa \
            --commit-message "FastChat LoRA 微调 Qwen-7B 高中学习助手"
