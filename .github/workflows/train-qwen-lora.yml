name: 微调 Qwen-7B 高中学习助手（FastChat + LoRA）
on:
  push:
    branches: [ main ]
  workflow_dispatch:

jobs:
  train-qwen-lora:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      packages: write
    steps:
      # 步骤 1：拉取仓库代码
      - name: 拉取代码
        uses: actions/checkout@v4

      # 步骤 2：配置 Conda + Python 3.10（无需 environment.yml）
      - name: 配置 Conda + CUDA 11.8
        uses: conda-incubator/setup-miniconda@v3
        with:
          auto-update-conda: true
          python-version: 3.10  # 直接指定 Python 版本
          activate-environment: fastchat-env  # 自定义环境名称
          auto-activate-base: true
          conda-solver: libmamba

      # 步骤 3：激活 Conda 并安装依赖（所有依赖直接安装）
      - name: 安装 PyTorch、FastChat 及训练依赖
        shell: bash -l {0}  # 确保激活 Conda 环境
        run: |
          # 安装 CUDA 11.8 + PyTorch（Conda 自动处理兼容性）
          conda install pytorch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 pytorch-cuda=11.8 -c pytorch -c nvidia -y
          
          # 安装 FastChat
          pip install --upgrade pip
          pip install -e .
          
          # 安装其他训练依赖
          pip install transformers==4.37.2 accelerate==0.27.1 peft==0.8.2 datasets==2.14.6
          pip install huggingface-hub==0.20.3 sentencepiece==0.1.99

      # 步骤 4：登录 Hugging Face Hub
      - name: 登录 Hugging Face Hub
        shell: bash -l {0}
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          huggingface-cli login --token $HF_TOKEN

      # 步骤 5：下载 Qwen-7B 基础模型
      - name: 下载 Qwen-7B 模型
        shell: bash -l {0}
        run: |
          huggingface-cli download Qwen/Qwen-7B \
            --local-dir ./models/Qwen-7B \
            --local-dir-use-symlinks False

      # 步骤 6：执行 LoRA 微调（禁用 flash-attn）
      - name: 启动 Qwen 模型 LoRA 微调
        shell: bash -l {0}
        run: |
          python -m fastchat.train.train_lora \
            --model_name_or_path ./models/Qwen-7B \
            --data_path ./data/highschool_qa.json \
            --output_dir ./output/qwen-7b-highschool-lora \
            --per_device_train_batch_size=4 \
            --gradient_accumulation_steps=4 \
            --learning_rate=2e-4 \
            --num_train_epochs=3 \
            --logging_steps=10 \
            --save_steps=100 \
            --fp16=True \
            --lora_r=8 \
            --lora_alpha=16 \
            --lora_dropout=0.05 \
            --target_modules="q_proj,v_proj,k_proj,o_proj,gate_proj,up_proj,down_proj" \
            --peft_model_id ${{ secrets.HF_USERNAME }}/qwen-7b-highschool-qa \
            --push_to_hub=True \
            --no-flash-attn

      # 步骤 7：推送合并后的模型到 Hugging Face
      - name: 推送合并后的模型到 Hugging Face
        shell: bash -l {0}
        if: success()
        run: |
          python -m fastchat.model.push_to_hub \
            --model-path ./models/Qwen-7B \
            --lora-path ./output/qwen-7b-highschool-lora \
            --repo-id ${{ secrets.HF_USERNAME }}/qwen-7b-highschool-qa \
            --commit-message "FastChat LoRA 微调 Qwen-7B 高中学习助手"
